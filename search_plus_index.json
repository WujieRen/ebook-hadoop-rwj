{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction Apache Hadoop软件库是一个框架，该框架允许使用简单的编程模型跨计算机集群对大型数据集进行分布式处理。它旨在从单个服务器扩展到数千台机器，每台机器都提供本地的计算和存储。集群的每台计算机都可能会出现故障，所以该库本身不依赖于硬件来提供高可用性，而是被设计用来检测和处理应用程序层的故障，因此可以在计算机集群的顶部提供高可用性服务。 本文档旨在以简单粗报直接的方式帮助大家使用Hadoop。使用的版本是Hadoop2.7.X。 下载 单击此处下载Apache Hadoop™。 Hadoop的特性 可靠性，高容错 存储的可靠性 HDFS以块（block）的形式来存储数据，Hadoop 1.X版本中块大小是64MB；Hadoop 2.X版本中块的大小为128MB。用户可自定义块大小 HDFS分布式的存储文件块到集群的多台机器上，每台保存一个副本。用户可以自己设置副本数。 对每个存储块文件生成也给校验码，之后定期检测或读取到这个块的时候又会生成一个校验码进行匹配，没匹配上说明文件损坏，Hadoop会自动重新创建一个副本以保证数据的安全性。 计算的可靠性 可扩展性 集群扩容 损坏的硬件重新上架 By renwujie            updated 2021-01-23 23:18:27 "},"01-cluster-setup/":{"url":"01-cluster-setup/","title":"Cluster Setup","keywords":"","body":"集群安装 Purpose 本节描述如何搭建一个完全分布式的Hadoop集群，以3台服务器举例。可扩展到若干节点。本文档不涉及安全或高可用性等主题。 Prerequisites 参考：搭建高可用集群时Linux环境必需配置的先决条件，先将Linux基础环境搭建成功。 Installation 点击下载相应版本，本文档采用2.7.7。安装Hadoop集群需要解压所软件在所有的节点上，所以将硬件的功能进行划分很重要。 建议将NameNode和ResourceManager指定分开在两台节点上，这样即使某台节点挂了也不至于导致NameNode和ResoureManager同时挂掉。其余的节点则同时充当DataNode和NodeManager。 n1（n1.com.rwj） n2（n2.com.rwj） n3（n3.com.rwj） NameNode/DataNode DataNode DataNode NodeManager NodeManager ResourceManager/NodeManager SecondaryNameNode HistoryServer Configure Hadoop HDFS的守护程序是NameNode，SecondaryNameNode和DataNode。 YARN守护程序是ResourceManager，NodeManager和WebAppProxy。如果要使用MapReduce，则MapReduce作业历史服务器也将运行。对于大型安装，它们通常在单独的主机上运行。 所有配置文件都在路径：$HADOOP_HOME/etc/hadoop 中。 配置JAVA_HOME变量 在hadoop-env.sh、yarn-env.sh、mapred-env.sh中指定JAVA_HOME的路径。 HDFS 配置hdfs文件系统的主机和端口，端口号在hadoop1.x版本默认使用的是9000，而在hadoop2.x中默认使用的是8020。 以及hadoop分布式集群经过格式化后数据保存的位置。 core-site.xml中配置： fs.defaultFS hdfs://n1.com.rwj:8020 hadoop.tmp.dir /opt/app/hadoop-2.7.0/data/tmp 在静态web页面上呈现内容时，以参数hadoop.http.staticuser.user指定的用户名作为筛选条件，默认dr.who。 core-site.xml中配置： hadoop.http.staticuser.user renwujie 测试环境可以关闭hdfs中文件访问权限，默认为true。 hdfs-site.xml中配置： dfs.permissions.enabled false YARN 配置ResourceManager的主机名；以及web访问地址。 yarn-site.xml中配置： yarn.resourcemanager.hostname n3.com.rwj yarn.resourcemanager.webapp.address ${yarn.resourcemanager.hostname}:8088 配置执行MapReduce job的框架。可选值：local，classic，yarn。 mapred-site.xml 中配置： mapreduce.framework.name yarn 如果在mapred-site.xml中设置了mapreduce.framework.name为yarn的话，就需要配置yarn.nodemanager.aux-services参数了。该参数用于指定执行MapReduce job时，yarn使用的shuffle（混淆）技术。如果使用的话值为mapreduce_shuffle。 yarn-site.xml中配置： yarn.nodemanager.aux-services mapreduce_shuffle--> A comma separated list of services where service name should only contain a-zA-Z0-9_ and can not start with numbers SecondaryNameNode hdfs-site.xml中配置： dfs.namenode.secondary.http-address n1.com.rwj:50090 HistoryServer mapred-site.xml中配置： mapreduce.jobhistory.address n2.com.rwj:10020 mapreduce.jobhistory.webapp.address n2.com.rwj:19888 日志聚合 yarn-site.xml中配置： yarn.log-aggregation-enable true yarn.log-aggregation.retain-seconds 106800 Slaves文件 slaves文件用于指定DataNode和NodeManager所在节点，每行一个。 n1.com.rwj n2.com.rwj n3.com.rwj Operating the Hadoop Cluster 完成以上配置后，将整个$HADOOP_HOME文件分发到集群中的所有节点上。分发前删除掉：$HADOOP_HOME/share/doc目录。因为该目录只是一些参考文档，且很大。分发时将占用大量带宽，浪费时间。 scp -r $HADOOP_HOME root@n2.com.rwj:/opt/ scp -r $HADOOP_HOME root@n3.com.rwj:/opt/ 格式化集群 要启动hadoop集群，需要将HDFS和YARN都启动。 首次启动HDFS时，需要将其格式化。在NameNode机器所在节点上执行： $ HADOOP_HOME / bin / hdfs namenode -format 启动/关闭集群 以下所有命令是启动命令，如果是关闭，将start替换为stop即可 启动HDFS： # 使用 $HADOOP_HOME/sbin/hadoop-daemon.sh start namenode $HADOOP_HOME/sbin/ hadoop-daemon.sh start datanode # 或者 $HADOOP_HOME/sbin/start-dfs.sh 启动YARN： # 使用 $HADOOP_HOME/sbin/yarn-daemon.sh start resourcemanager $HADOOP_HOME/sbin/yarn-daemon.sh start nodemanager # 或者 $HADOOP_HOME/sbin/start-yarn.sh 启动HistoryServer $HADOOP_HOME/bin/mapred --daemon start historyserver Web Interface 成功启动集群后即可查看对应组件的Web UI是否可以正常访问。 Daemon Web Interface Notes NameNode https://n1.com.rwj:50070 默认50070 ResourceManager https://n1.com.rwj:8088 默认8088 MapReduce JobHistory https://n1.com.rwj:19888 默认19888 By renwujie            updated 2021-01-24 18:35:25 "},"01-cluster-setup/01-FAQ.html":{"url":"01-cluster-setup/01-FAQ.html","title":"FAQ","keywords":"","body":" By renwujie            updated 2021-01-24 00:20:29 "},"02-architecture/":{"url":"02-architecture/","title":"Architecture","keywords":"","body":" By renwujie            updated 2021-01-24 00:17:39 "},"02-architecture/01-hdfs/":{"url":"02-architecture/01-hdfs/","title":"Hdfs","keywords":"","body":" By renwujie            updated 2021-01-24 00:18:12 "},"03/":{"url":"03/","title":"03","keywords":"","body":" By renwujie            updated 2021-01-24 00:17:39 "},"11-src-code/":{"url":"11-src-code/","title":"Src Code","keywords":"","body":" By renwujie            updated 2021-01-23 23:35:22 "},"11-src-code/01-build/":{"url":"11-src-code/01-build/","title":"Build","keywords":"","body":"简介 源码修改后要先编译，这里就以一个简单的例子去编译。代码修改给超链接到本章的具体页面中。 By renwujie            updated 2021-01-24 00:17:56 "}}